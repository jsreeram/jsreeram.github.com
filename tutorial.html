<!DOCTYPE html>
<html>

    <head>
        <meta charset='utf-8' />
        <meta http-equiv="X-UA-Compatible" content="chrome=1" />
        <meta name="description" content="Jsreeram.github.com : jsreeram.github.com" />

        <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

        <title>River Trail</title>
        <script type="text/javascript">
            var fixGistRules = [
            ".gist .gist-highlight {  border-left: 3ex solid #eee;  position: relative;}",
            ".gist .gist-highlight pre { counter-reset: linenumbers;}",
            ".gist .gist-highlight pre div:before { color: #aaa; content: counter(linenumbers); counter-increment: linenumbers;  left: -3ex; position: absolute; text-align: right; width: 2.5ex;}" ];

var head = document.getElementsByTagName('head')[0],
    style = document.createElement('style');

rules = new Array();
var i=0;
for ( i=0; i< fixGistRules.length; i++ ){
    var fullrule = document.createTextNode(fixGistRules[i]);
    rules.push(fullrule);
}

style.type = 'text/css';

for ( var i=0; i< rules.length; i++ ){
    if(style.styleSheet){
        style.styleSheet.cssText = rules[i].nodeValue;
    }else {
        style.appendChild(rules[i]);
        head.appendChild(style);
    }
}
</script>
<script type="text/javascript" src="javascripts/XRegExp.js"></script> <!-- XRegExp is bundled with the final shCore.js during build -->
	<script type="text/javascript" src="javascripts/shCore.js"></script>
	<script type="text/javascript" src="javascripts/shBrushJScript.js"></script>
	<link type="text/css" rel="stylesheet" href="stylesheets/shCoreDefault.css"/>
	<link type="text/css" rel="Stylesheet" href="stylesheets/shThemeDefault.css" />
	<script type="text/javascript">SyntaxHighlighter.all();</script>

  </head>

  <body>

      <!-- HEADER -->
      <div id="header_wrap" class="outer">
          <header class="inner">
          <a id="forkme_banner" href="https://github.com/rivertrail/rivertrail">View on GitHub</a>

          <h1 id="project_title">Build a web app with River Trail</h1>
          <h2 id="project_tagline">jsreeram.github.com</h2>

          </header>
      </div>

      <!-- MAIN CONTENT -->
      <div id="main_content_wrap" class="outer">
          <section id="main_content" class="inner">

          In this hands-on tutorial we will use the River Trail in a sample HTML5
          video application. If you haven't already, read the <a
              href="index.html">API description</a> and come back. It is also a
          good idea to have this API description to refer to.
          <h2>Setup </h2>
          <h3>Download and Install</h3>If you have not already, <a
              href="https://github.com/RiverTrail/RiverTrail/wiki">download
              and install River Trail</a>.
          To be able to use a video stream from a webcam you will also need
          Rainbow.
          <h3>Configure</h3>
          Because of Firefox's security policies, you may have to
          install Apache (or any other webserver) and configure it so that
          it serves files from the River Trail directory.
          <h3>Verify</h3> Check if you can run the examples in
          <em>rivertrail/examples </em> by loading them in Firefox. If you can, you are good to go.
          <h2> The Skeleton </h2>
          The directory <em>rivertrail/examples/video-app</em> contains a
          skeleton for the video application that you can start with. Load up
          the <em>index.html</em> file in this directory in Firefox and you should see the
          default screen for the application skeleton:
          <img src="images/v2.png"/>
          The large box in the center is a <a
              href="https://developer.mozilla.org/en-US/docs/Canvas_tutorial">
              Canvas </a> that is used for rendering the video output. The
          video input is either a HTML5 video stream embedded in a <a href
              ="https://developer.mozilla.org/en-US/docs/HTML/Element/video">
              video tag </a> or live video caputured by a webcam. On the
          left of the screen you will see the various filters that can applied
          to this input video stream - sepia toning, lightening, desaturation
          etc. Click on the box in the center screen to start playback and try
          out these filters. To switch to webcam video, click the "Webcam" toggle in
          the top-left corner.

          The sequential JavaScript versions of the filters on the right are already
          implemented and in this tutorial we will implement the "parallel"
          versions using River Trail. Before we dive into implementation, lets
          look at the basics of manipulating video using the Canvas API.

          <h2> Manipulating pixels on Canvas </h2>
          Open up main.js in your favorite code editor. This file implements
          all the functionality in this web application except the filters
          themselves. When you load the page, the "doLoad()" function is called
          after the body of the webpage has been loaded. This function sets up
          the drawing contexts, initializes the list of filters (or kernels)
          and assigns a click event handler for the output canvas.

          The computeFrame() function is the workhorse that reads an input
          video frame, applies all the selected filters on it to produce an
          output frame that is written to the output canvas context.
          The code above shows how a frame from a HTML video element is drawn to a 2D
          context associated with a canvas element.
          
          <!--<p><script
              src="http://gist.github.com/3419413.js#L2"></script></p>-->
<pre class="brush: js;first-line: 240">
// main.js : computeFrame()
output_context.drawImage(video, 0, 0, output_canvas.width,
    output_canvas.height);
</pre>
          After this video frame is drawn to canvas, we need to capture the
          pixels so that we can apply our filters. This is done by calling
          getImageData() on the context containing the image we want to
          capture.
<pre class="brush: js;first-line: 248">
// main.js : computeFrame(), line number 249
frame = input_context.getImageData(0, 0, input_canvas.width,
    input_canvas.height);
len = frame.data.length;
w = frame.width ; h = frame.height;
</pre>

Now we have an <a
href="https://developer.mozilla.org/en-US/docs/HTML/Canvas/Pixel_manipulation_with_canvas">ImageData</a> object called "frame". The "data" attribute of this
object contains the pixel information and the "width"/"height" attributes
contain the dimensions of the image we have captured.

The data attribute contains RGBA values for each pixel in a row-major format.
That is, for a frame with h rows of pixels and w columns, it contains an array
of length w * h * 4 as shown below:<br>
<img src="images/imgdata.png" width="300"/><br>

So for example to get the color values of a pixel in the 100th row and
50th column in the image, we would do:
<pre class="brush: js;first-line: 1">
var red   = frame.data[100*w*4 + 50*4 + 0];
var green = frame.data[100*w*4 + 50*4 + 1];
var blue  = frame.data[100*w*4 + 50*4 + 2];
var alpha = frame.data[100*w*4 + 50*4 + 3];
</pre>

To set, for example the red value of this pixel, simply write the new value at the
offset shown above in the frame.data buffer.

          <h2> Sepia Toning </h2>
          <a
              href="http://en.wikipedia.org/wiki/Photographic_print_toning#Sepia_toning">Sepia
              Toning</a> is a process performed on black-and-white print
          photographs to give them a warmer color. This filter simulates the
          sepia toning process on digital photographs or video.
          <img src="images/se1.png" height="170"/>
          <img src="images/se2.png" height="170"/>
    
          Let us first look at the sequential implementation of this filter in
          the function called <code>sepia_sequential()</code> in filters.js.

            <pre class="brush: js;first-line: 819">
function sepia_sequential(frame, len, w, h, ctx) {
    var pix = frame.data;
    var r = 0, g = 0, b = 0;
    for(var i = 0 ; i < len; i = i+4) {
        r = (pix[i] * 0.393 + pix[i+1] * 0.769 + pix[i+2] * 0.189);
        g = (pix[i] * 0.349 + pix[i+1] * 0.686 + pix[i+2] * 0.168);
        b = (pix[i] * 0.272 + pix[i+1] * 0.534 + pix[i+2] * 0.131);
        
        if(r>255) r = 255;
        if(g>255) g = 255;
        if(b>255) b = 255;

        if(r<0) r = 0;
        if(g<0) g = 0;
        if(b<0) b = 0;

        pix[i] = r;
        pix[i+1] = g;
        pix[i+2] = b;
    }
    ctx.putImageData(frame, 0, 0);
} 
            </pre>

          Remember from the previous snippet that the frame.data buffer
          contains color values as <strong>rgbargbargba...</strong>. The
          <code>for</code> loop in line 822
          iterates over this buffer and for each pixel it reads the red, green
          and blue values which are in pix[i], pix[i+1], pix[i+2] respectively.
          It computes a weighted average of these colors to produce the new
          red, green, blue values for that pixel.



          </section>
      </div>

      <!-- FOOTER  -->
      <div id="footer_wrap" class="outer">
          <footer class="inner">
          <p>&copy; 2012 Jaswanth Sreeram. Published with <a href="http://pages.github.com">GitHub Pages</a></p>
          </footer>
      </div>



  </body>
</html>
